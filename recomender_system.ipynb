{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>DLRM model</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import depencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fbgemm-gpu\n",
    "# !pip install fbgemm-gpu-cpu\n",
    "# !pip install torch\n",
    "# !pip install torchrec\n",
    "# !pip install torchrec-cpu\n",
    "# !pip install pyre_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch     \n",
    "from sklearn.model_selection import train_test_split\n",
    "#import custom function from book_funcs file\n",
    "from book_funcs import category_cleaner, df_cleaner, category_cleaner,\n",
    "category_compliter, zero_droper, precentage_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'/Users/royzalta/Downloads/archive/Books Data with Category Language and Summary/Preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = df['age'].astype(int)\n",
    "df['year_of_publication'] = df['year_of_publication'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train & test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    df, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply custom transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original data frame shape:\t(690887, 19)\n",
      "The data frame shape after bookk filtering:\t(376474, 19)\n",
      "The new data frame shape:\t(340545, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/royzalta/Documents/GitHub/books_recom_sys/book_funcs.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_author9_relevant_two_options['pred_Category'] = df_author9_relevant_two_options['Category'].apply(\n"
     ]
    }
   ],
   "source": [
    "train_df = category_cleaner(train_df)\n",
    "train_df = df_cleaner(train_df)\n",
    "train_df = category_compliter(train_df)\n",
    "train_df = zero_droper(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 121040 entries, 0 to 121039\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count   Dtype \n",
      "---  ------               --------------   ----- \n",
      " 0   user_id              121040 non-null  int64 \n",
      " 1   location             121040 non-null  object\n",
      " 2   age                  121040 non-null  int64 \n",
      " 3   isbn                 121040 non-null  object\n",
      " 4   rating               121040 non-null  int64 \n",
      " 5   book_title           121040 non-null  object\n",
      " 6   book_author          121040 non-null  object\n",
      " 7   year_of_publication  121040 non-null  int64 \n",
      " 8   publisher            121040 non-null  object\n",
      " 9   img_s                121040 non-null  object\n",
      " 10  img_m                121040 non-null  object\n",
      " 11  img_l                121040 non-null  object\n",
      " 12  Summary              121040 non-null  object\n",
      " 13  Language             121040 non-null  object\n",
      " 14  Category             121040 non-null  object\n",
      " 15  city                 118306 non-null  object\n",
      " 16  state                117203 non-null  object\n",
      " 17  country              114898 non-null  object\n",
      "dtypes: int64(4), object(14)\n",
      "memory usage: 16.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to check for nulls \n",
    "def precentage_null(df):\n",
    "    null_count = df.isnull().sum()\n",
    "    total_count = len(df)\n",
    "    print((null_count/total_count) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id                0.000000\n",
      "location               0.000000\n",
      "age                    0.000000\n",
      "isbn                   0.000000\n",
      "rating                 0.000000\n",
      "book_title             0.000000\n",
      "book_author            0.000000\n",
      "year_of_publication    0.000000\n",
      "publisher              0.000000\n",
      "img_s                  0.000000\n",
      "img_m                  0.000000\n",
      "img_l                  0.000000\n",
      "Summary                0.000000\n",
      "Language               0.000000\n",
      "Category               0.000000\n",
      "city                   2.258757\n",
      "state                  3.170026\n",
      "country                5.074356\n",
      "location_enc           0.000000\n",
      "publisher_enc          0.000000\n",
      "Language_enc           0.000000\n",
      "Category_enc           0.000000\n",
      "dtype: float64\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "null_train = precentage_null(train_df)\n",
    "print(null_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding sparse features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_dense = [\"age\", \"year_of_publication\"]\n",
    "cols_sparse = ['location',\n",
    "               'publisher','Language','Category',\n",
    "              'city','state','country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(col, map_rev):\n",
    "    encoded_values = []\n",
    "    for item in col:\n",
    "        if pd.notna(item):  # Check if the value is not NaN\n",
    "            encoded_value = map_rev.get(item, item)\n",
    "            encoded_values.append(encoded_value)\n",
    "        else:\n",
    "            # Handle NaN values as needed\n",
    "            encoded_values.append('NaN')\n",
    "    return encoded_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_sparse = {}\n",
    "map_sparse_rev = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m map_sparse[feat] \u001b[38;5;241m=\u001b[39m {i: c \u001b[38;5;28;01mfor\u001b[39;00m i,c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_df[feat]\u001b[38;5;241m.\u001b[39mexplode()\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mindex)}\n\u001b[1;32m      3\u001b[0m map_sparse_rev[feat] \u001b[38;5;241m=\u001b[39m {v:k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m map_sparse[feat]\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m----> 5\u001b[0m train_df[feat\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_enc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train_df[feat]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: encode(x, map_sparse_rev[feat]))\n\u001b[1;32m      6\u001b[0m test_df[feat\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_enc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test_df[feat]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: encode(x, map_sparse_rev[feat]))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\u001b[38;5;28mself\u001b[39m, func, convert_dtype, args, kwargs)\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1174\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmap_infer(\n\u001b[1;32m   1175\u001b[0m             values,\n\u001b[1;32m   1176\u001b[0m             f,\n\u001b[1;32m   1177\u001b[0m             convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype,\n\u001b[1;32m   1178\u001b[0m         )\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m map_sparse[feat] \u001b[38;5;241m=\u001b[39m {i: c \u001b[38;5;28;01mfor\u001b[39;00m i,c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_df[feat]\u001b[38;5;241m.\u001b[39mexplode()\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mindex)}\n\u001b[1;32m      3\u001b[0m map_sparse_rev[feat] \u001b[38;5;241m=\u001b[39m {v:k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m map_sparse[feat]\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m----> 5\u001b[0m train_df[feat\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_enc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train_df[feat]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: encode(x, map_sparse_rev[feat]))\n\u001b[1;32m      6\u001b[0m test_df[feat\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_enc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test_df[feat]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: encode(x, map_sparse_rev[feat]))\n",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m, in \u001b[0;36mencode\u001b[0;34m(col, map_rev)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(col, map_rev):\n\u001b[1;32m      2\u001b[0m     encoded_values \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m col:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotna(item):  \u001b[38;5;66;03m# Check if the value is not NaN\u001b[39;00m\n\u001b[1;32m      5\u001b[0m             encoded_value \u001b[38;5;241m=\u001b[39m map_rev\u001b[38;5;241m.\u001b[39mget(item, item)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "for feat in cols_sparse:\n",
    "    map_sparse[feat] = {i: c for i,c in enumerate(train_df[feat].explode().value_counts().index)}\n",
    "    map_sparse_rev[feat] = {v:k for k, v in map_sparse[feat].items()}\n",
    "\n",
    "    train_df[feat+'_enc'] = train_df[feat].apply(lambda x: encode(x, map_sparse_rev[feat]))\n",
    "    test_df[feat+'_enc'] = test_df[feat].apply(lambda x: encode(x, map_sparse_rev[feat]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
