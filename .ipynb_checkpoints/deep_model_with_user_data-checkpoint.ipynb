{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab209f5b",
   "metadata": {},
   "source": [
    "משימות:\n",
    "1. לייצר פיצ'רים מטמטיים מהקטגוריות והתקצירים - בוצע\n",
    "2.  לחבר אותם לאינדקסים של הטבלה לפי הקטגוריות - בוצע\n",
    "3. ליצור קובץ שלהם- בוצע\n",
    "4. להכניס אותם למודל כשכבה נפרדת, להבין כיצד נכון לשלב את זה - בוצע \n",
    "5. לחזות - בוצע\n",
    "6. ליצור מודל \"ברירת מחדל\" שממליץ על פופולריות\n",
    "7. לראות איך משבים ריקול ופרפ גם למודל הזה\n",
    "8. לשקול לסנן קוראים עם פחות מ10 ספרים\n",
    "9. להוסיף למצגת"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff9f9049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, pydot, graphviz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "# Split the data into train and test sets\n",
    "# importing relevant libraries\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5354b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pydot\n",
    "import pydotplus\n",
    "from pydotplus import graphviz\n",
    "from keras.utils import plot_model\n",
    "from keras.utils import model_to_dot\n",
    "keras.utils.pydot = pydot\n",
    "#plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94c5b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fd1962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reader_encode(df,y=None):\n",
    "\n",
    "    cat_var = ['Language','country']\n",
    "    one_hot = OneHotEncoder(sparse=False)  # , drop = 'first')\n",
    "    encoder_var_array = one_hot.fit_transform(df[cat_var])\n",
    "    encoder_name = one_hot.get_feature_names_out(cat_var)\n",
    "    encoder_vars_df = pd.DataFrame(encoder_var_array, columns=encoder_name)\n",
    "    df = pd.concat([df, encoder_vars_df], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1400d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4e3b9c",
   "metadata": {},
   "source": [
    "יש לנו בעיה בשימוש במשתנים האלה, יש הרבה מאוד ספרים שאין להם קטגוריה, אפשר להזין להם 0, אבל זה עדיין יהיה בעל משמעות מסוימת וזה לא יהיה נכון"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38df40b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\yotam\\Desktop\\naya\\df_clean_after_pca')\n",
    "df = df[df['rating']!=0]\n",
    "df_isbn = df['isbn']\n",
    "num_dict = {}\n",
    "for i,j in enumerate(df_isbn.unique()):\n",
    "    num_dict[j]=i\n",
    "df['isbn_num'] = df['isbn'].apply(lambda txt: num_dict[txt])\n",
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6987069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>user_id</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>...</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>isbn_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>timmins, ontario, canada</td>\n",
       "      <td>34.7439</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>5</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03518</td>\n",
       "      <td>-0.125755</td>\n",
       "      <td>-0.019404</td>\n",
       "      <td>0.044569</td>\n",
       "      <td>-0.040087</td>\n",
       "      <td>0.005104</td>\n",
       "      <td>0.023391</td>\n",
       "      <td>0.116895</td>\n",
       "      <td>0.013755</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11676</td>\n",
       "      <td>n/a, n/a, n/a</td>\n",
       "      <td>34.7439</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>8</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03518</td>\n",
       "      <td>-0.125755</td>\n",
       "      <td>-0.019404</td>\n",
       "      <td>0.044569</td>\n",
       "      <td>-0.040087</td>\n",
       "      <td>0.005104</td>\n",
       "      <td>0.023391</td>\n",
       "      <td>0.116895</td>\n",
       "      <td>0.013755</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>67544</td>\n",
       "      <td>toronto, ontario, canada</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>8</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03518</td>\n",
       "      <td>-0.125755</td>\n",
       "      <td>-0.019404</td>\n",
       "      <td>0.044569</td>\n",
       "      <td>-0.040087</td>\n",
       "      <td>0.005104</td>\n",
       "      <td>0.023391</td>\n",
       "      <td>0.116895</td>\n",
       "      <td>0.013755</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>116866</td>\n",
       "      <td>ottawa, ,</td>\n",
       "      <td>34.7439</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>9</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03518</td>\n",
       "      <td>-0.125755</td>\n",
       "      <td>-0.019404</td>\n",
       "      <td>0.044569</td>\n",
       "      <td>-0.040087</td>\n",
       "      <td>0.005104</td>\n",
       "      <td>0.023391</td>\n",
       "      <td>0.116895</td>\n",
       "      <td>0.013755</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>200273</td>\n",
       "      <td>comber, ontario, canada</td>\n",
       "      <td>34.7439</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>8</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03518</td>\n",
       "      <td>-0.125755</td>\n",
       "      <td>-0.019404</td>\n",
       "      <td>0.044569</td>\n",
       "      <td>-0.040087</td>\n",
       "      <td>0.005104</td>\n",
       "      <td>0.023391</td>\n",
       "      <td>0.116895</td>\n",
       "      <td>0.013755</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 251 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index  user_id                  location      age        isbn  \\\n",
       "0           0      0        8  timmins, ontario, canada  34.7439  0002005018   \n",
       "1           2      2    11676             n/a, n/a, n/a  34.7439  0002005018   \n",
       "2           4      4    67544  toronto, ontario, canada  30.0000  0002005018   \n",
       "3           7      7   116866                 ottawa, ,  34.7439  0002005018   \n",
       "4           9      9   200273   comber, ontario, canada  34.7439  0002005018   \n",
       "\n",
       "   rating    book_title           book_author  year_of_publication  ...  \\\n",
       "0       5  Clara Callan  Richard Bruce Wright               2001.0  ...   \n",
       "1       8  Clara Callan  Richard Bruce Wright               2001.0  ...   \n",
       "2       8  Clara Callan  Richard Bruce Wright               2001.0  ...   \n",
       "3       9  Clara Callan  Richard Bruce Wright               2001.0  ...   \n",
       "4       8  Clara Callan  Richard Bruce Wright               2001.0  ...   \n",
       "\n",
       "       221       222       223       224       225       226       227  \\\n",
       "0  0.03518 -0.125755 -0.019404  0.044569 -0.040087  0.005104  0.023391   \n",
       "1  0.03518 -0.125755 -0.019404  0.044569 -0.040087  0.005104  0.023391   \n",
       "2  0.03518 -0.125755 -0.019404  0.044569 -0.040087  0.005104  0.023391   \n",
       "3  0.03518 -0.125755 -0.019404  0.044569 -0.040087  0.005104  0.023391   \n",
       "4  0.03518 -0.125755 -0.019404  0.044569 -0.040087  0.005104  0.023391   \n",
       "\n",
       "        228       229 isbn_num  \n",
       "0  0.116895  0.013755        0  \n",
       "1  0.116895  0.013755        0  \n",
       "2  0.116895  0.013755        0  \n",
       "3  0.116895  0.013755        0  \n",
       "4  0.116895  0.013755        0  \n",
       "\n",
       "[5 rows x 251 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea3a5b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_author = df['book_author']\n",
    "num_dict = {}\n",
    "for i,j in enumerate(book_author.unique()):\n",
    "    num_dict[j]=i\n",
    "df['author_num'] = df['book_author'].apply(lambda txt: num_dict[txt])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42409858",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df =reader_encode(df)\n",
    "#לשקול לעשות פה שאפל מוגדר\n",
    "train_users, test_users = train_test_split(df, test_size = 0.2 , random_state= 42)\n",
    "x_train = train_users.drop(columns=['rating'])\n",
    "y_train = train_users[\"rating\"]\n",
    "\n",
    "x_test = test_users.drop(columns=['rating'])\n",
    "y_test = test_users[\"rating\"]\n",
    "all_users = train_users[\"user_id\"].unique()\n",
    "all_books = train_users[\"isbn_num\"].unique()\n",
    "all_authors = train_users[\"author_num\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cdeb039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(r'/Users/royzalta/Downloads/archive/Books Data with Category Language and Summary/Preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "210bda7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(r\"C:\\Users\\yotam\\Desktop\\naya\\Preprocessed_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f0e259",
   "metadata": {},
   "source": [
    "## Implemation of TenserFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dafdb7",
   "metadata": {},
   "source": [
    "### naive model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf0ed77",
   "metadata": {},
   "source": [
    "# full pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2a4b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = tf.keras.layers.Input(shape=(1,), name=\"user\")\n",
    "user_as_integer = tf.keras.layers.IntegerLookup(vocabulary=all_users)(user_input)\n",
    "user_embedding = tf.keras.layers.Embedding(input_dim=len(all_users) + 1, output_dim=32)(user_as_integer)\n",
    "user_bias = tf.keras.layers.Embedding(input_dim=len(all_users) + 1, output_dim=1)(user_as_integer)\n",
    "\n",
    "book_input = tf.keras.layers.Input(shape=(1,), name=\"book\")\n",
    "book_as_integer = tf.keras.layers.IntegerLookup(vocabulary=all_books)(book_input)\n",
    "book_embedding = tf.keras.layers.Embedding(input_dim=len(all_books) + 1, output_dim=32)(book_as_integer)\n",
    "book_bias = tf.keras.layers.Embedding(input_dim=len(all_books) + 1, output_dim=1)(book_as_integer)\n",
    "\n",
    "dot = tf.keras.layers.Dot(axes=2)([user_embedding, book_embedding])\n",
    "add = tf.keras.layers.Add()([dot, user_bias, book_bias])\n",
    "flatten = tf.keras.layers.Flatten()(add)\n",
    "squash = tf.keras.layers.Lambda(lambda x: 9 * tf.nn.sigmoid(x) + 1)(flatten)\n",
    "\n",
    "model = tf.keras.Model(inputs=[user_input, book_input], outputs=squash)\n",
    "\n",
    "\n",
    "model.compile(loss=\"mse\", metrics=[tf.keras.metrics.MeanAbsoluteError(),tf.keras.metrics.RootMeanSquaredError()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b44ad00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " user (InputLayer)           [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " book (InputLayer)           [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " integer_lookup_2 (IntegerL  (None, 1)                    0         ['user[0][0]']                \n",
      " ookup)                                                                                           \n",
      "                                                                                                  \n",
      " integer_lookup_3 (IntegerL  (None, 1)                    0         ['book[0][0]']                \n",
      " ookup)                                                                                           \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)     (None, 1, 32)                767456    ['integer_lookup_2[0][0]']    \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)     (None, 1, 32)                953120    ['integer_lookup_3[0][0]']    \n",
      "                                                                                                  \n",
      " dot_1 (Dot)                 (None, 1, 1)                 0         ['embedding_2[0][0]',         \n",
      "                                                                     'embedding_4[0][0]']         \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)     (None, 1, 1)                 23983     ['integer_lookup_2[0][0]']    \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)     (None, 1, 1)                 29785     ['integer_lookup_3[0][0]']    \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 1, 1)                 0         ['dot_1[0][0]',               \n",
      "                                                                     'embedding_3[0][0]',         \n",
      "                                                                     'embedding_5[0][0]']         \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 1)                    0         ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " lambda (Lambda)             (None, 1)                    0         ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1774344 (6.77 MB)\n",
      "Trainable params: 1774344 (6.77 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1eb7fa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1164/1164 [==============================] - 12s 10ms/step - loss: 7.4251 - mean_absolute_error: 2.3758 - root_mean_squared_error: 2.7249 - val_loss: 6.8057 - val_mean_absolute_error: 2.2563 - val_root_mean_squared_error: 2.6088\n",
      "Epoch 2/20\n",
      "1164/1164 [==============================] - 12s 10ms/step - loss: 6.3311 - mean_absolute_error: 2.1628 - root_mean_squared_error: 2.5162 - val_loss: 5.9958 - val_mean_absolute_error: 2.0909 - val_root_mean_squared_error: 2.4486\n",
      "Epoch 3/20\n",
      "1164/1164 [==============================] - 11s 9ms/step - loss: 5.5415 - mean_absolute_error: 1.9950 - root_mean_squared_error: 2.3540 - val_loss: 5.4209 - val_mean_absolute_error: 1.9672 - val_root_mean_squared_error: 2.3283\n",
      "Epoch 4/20\n",
      "1164/1164 [==============================] - 12s 10ms/step - loss: 4.9245 - mean_absolute_error: 1.8545 - root_mean_squared_error: 2.2191 - val_loss: 4.9960 - val_mean_absolute_error: 1.8713 - val_root_mean_squared_error: 2.2352\n",
      "Epoch 5/20\n",
      "1164/1164 [==============================] - 11s 9ms/step - loss: 4.4186 - mean_absolute_error: 1.7314 - root_mean_squared_error: 2.1021 - val_loss: 4.6760 - val_mean_absolute_error: 1.7964 - val_root_mean_squared_error: 2.1624\n",
      "Epoch 6/20\n",
      "1164/1164 [==============================] - 11s 9ms/step - loss: 3.9906 - mean_absolute_error: 1.6216 - root_mean_squared_error: 1.9976 - val_loss: 4.4326 - val_mean_absolute_error: 1.7377 - val_root_mean_squared_error: 2.1054\n",
      "Epoch 7/20\n",
      "1164/1164 [==============================] - 11s 9ms/step - loss: 3.6207 - mean_absolute_error: 1.5216 - root_mean_squared_error: 1.9028 - val_loss: 4.2456 - val_mean_absolute_error: 1.6914 - val_root_mean_squared_error: 2.0605\n",
      "Epoch 8/20\n",
      "1164/1164 [==============================] - 10s 9ms/step - loss: 3.2943 - mean_absolute_error: 1.4295 - root_mean_squared_error: 1.8150 - val_loss: 4.1004 - val_mean_absolute_error: 1.6542 - val_root_mean_squared_error: 2.0249\n",
      "Epoch 9/20\n",
      "1164/1164 [==============================] - 11s 9ms/step - loss: 3.0018 - mean_absolute_error: 1.3431 - root_mean_squared_error: 1.7326 - val_loss: 3.9884 - val_mean_absolute_error: 1.6253 - val_root_mean_squared_error: 1.9971\n",
      "Epoch 10/20\n",
      "1164/1164 [==============================] - 10s 9ms/step - loss: 2.7368 - mean_absolute_error: 1.2615 - root_mean_squared_error: 1.6543 - val_loss: 3.9008 - val_mean_absolute_error: 1.6019 - val_root_mean_squared_error: 1.9750\n",
      "Epoch 11/20\n",
      "1164/1164 [==============================] - 11s 9ms/step - loss: 2.4949 - mean_absolute_error: 1.1839 - root_mean_squared_error: 1.5795 - val_loss: 3.8326 - val_mean_absolute_error: 1.5835 - val_root_mean_squared_error: 1.9577\n",
      "Epoch 12/20\n",
      "1164/1164 [==============================] - 11s 9ms/step - loss: 2.2742 - mean_absolute_error: 1.1104 - root_mean_squared_error: 1.5081 - val_loss: 3.7820 - val_mean_absolute_error: 1.5693 - val_root_mean_squared_error: 1.9447\n",
      "Epoch 13/20\n",
      "1164/1164 [==============================] - 11s 9ms/step - loss: 2.0725 - mean_absolute_error: 1.0407 - root_mean_squared_error: 1.4396 - val_loss: 3.7442 - val_mean_absolute_error: 1.5586 - val_root_mean_squared_error: 1.9350\n",
      "Epoch 14/20\n",
      "1164/1164 [==============================] - 11s 10ms/step - loss: 1.8887 - mean_absolute_error: 0.9749 - root_mean_squared_error: 1.3743 - val_loss: 3.7170 - val_mean_absolute_error: 1.5506 - val_root_mean_squared_error: 1.9280\n",
      "Epoch 15/20\n",
      "1164/1164 [==============================] - 11s 9ms/step - loss: 1.7210 - mean_absolute_error: 0.9127 - root_mean_squared_error: 1.3119 - val_loss: 3.6971 - val_mean_absolute_error: 1.5445 - val_root_mean_squared_error: 1.9228\n",
      "Epoch 16/20\n",
      "1164/1164 [==============================] - 11s 9ms/step - loss: 1.5687 - mean_absolute_error: 0.8543 - root_mean_squared_error: 1.2525 - val_loss: 3.6836 - val_mean_absolute_error: 1.5399 - val_root_mean_squared_error: 1.9193\n",
      "Epoch 17/20\n",
      "1164/1164 [==============================] - 11s 10ms/step - loss: 1.4303 - mean_absolute_error: 0.7994 - root_mean_squared_error: 1.1960 - val_loss: 3.6751 - val_mean_absolute_error: 1.5365 - val_root_mean_squared_error: 1.9171\n",
      "Epoch 18/20\n",
      "1164/1164 [==============================] - 11s 9ms/step - loss: 1.3046 - mean_absolute_error: 0.7482 - root_mean_squared_error: 1.1422 - val_loss: 3.6707 - val_mean_absolute_error: 1.5341 - val_root_mean_squared_error: 1.9159\n",
      "Epoch 19/20\n",
      "1164/1164 [==============================] - 11s 9ms/step - loss: 1.1905 - mean_absolute_error: 0.7002 - root_mean_squared_error: 1.0911 - val_loss: 3.6696 - val_mean_absolute_error: 1.5322 - val_root_mean_squared_error: 1.9156\n",
      "Epoch 20/20\n",
      "1164/1164 [==============================] - 11s 9ms/step - loss: 1.0869 - mean_absolute_error: 0.6556 - root_mean_squared_error: 1.0425 - val_loss: 3.6702 - val_mean_absolute_error: 1.5309 - val_root_mean_squared_error: 1.9158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1604776c4f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model.fit(\n",
    "     x={\n",
    "         \"user\": x_train[\"user_id\"],\n",
    "         \"book\": x_train[\"isbn_num\"]\n",
    "     },\n",
    "     y=y_train.values,\n",
    "     batch_size=128,\n",
    "     epochs=20,\n",
    "     validation_split=0.1, # for early stopping\n",
    "     callbacks=[\n",
    "         tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "     ],\n",
    " )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "100fcbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1293/1293 [==============================] - 3s 1ms/step - loss: 3.7359 - mean_absolute_error: 1.5488 - root_mean_squared_error: 1.9328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.7358641624450684, 1.5488183498382568, 1.9328383207321167]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate({\n",
    "    \"user\": x_test[\"user_id\"],#.reshape(-1, 1), # fill user 1 in many times\n",
    "    \"book\": x_test[\"isbn_num\"]#.reshape(-1, 1)\n",
    "},y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a792dd09",
   "metadata": {},
   "source": [
    " ### model with more inputs:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43717535",
   "metadata": {},
   "source": [
    " ### model with emmbeding category and summerys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4942386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = tf.keras.layers.Input(shape=(1,), name=\"user\")\n",
    "user_as_integer = tf.keras.layers.IntegerLookup(vocabulary=all_users)(user_input)\n",
    "user_embedding = tf.keras.layers.Embedding(input_dim=len(all_users) + 1, output_dim=32)(user_as_integer)\n",
    "user_bias = tf.keras.layers.Embedding(input_dim=len(all_users) + 1, output_dim=1)(user_as_integer)\n",
    "\n",
    "book_input = tf.keras.layers.Input(shape=(1,), name=\"book\")\n",
    "book_as_integer = tf.keras.layers.IntegerLookup(vocabulary=all_books)(book_input)\n",
    "book_embedding = tf.keras.layers.Embedding(input_dim=len(all_books) + 1, output_dim=32)(book_as_integer)\n",
    "book_bias = tf.keras.layers.Embedding(input_dim=len(all_books) + 1, output_dim=1)(book_as_integer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "feature_input = tf.keras.layers.Input(shape=(230,), name=\"user_book_data\")\n",
    "feature = tf.keras.layers.Dense(200, name=\"add_some_feature\")(feature_input)\n",
    "dropout1 = tf.keras.layers.Dropout(0.3, name=\"drop_some_feature\")(feature)\n",
    "feature2 = tf.keras.layers.Dense(64, activation = 'relu', name=\"add_some_feature2\")(dropout1)\n",
    "\n",
    "dot = tf.keras.layers.Dot(axes=2)([user_embedding, book_embedding])\n",
    "add = tf.keras.layers.Add()([dot, user_bias, book_bias])\n",
    "flatten = tf.keras.layers.Flatten()(add)\n",
    "con = tf.keras.layers.concatenate([flatten,feature2])\n",
    "dense2 = tf.keras.layers.Dense(128, activation = 'relu', name=\"dence_layer2\")(con)\n",
    "dropout2 = tf.keras.layers.Dropout(0.3, name=\"drop_some_feature3\")(dense2)\n",
    "dense3 = tf.keras.layers.Dense(64, activation = 'relu', name=\"dence_layer3\")(dropout2)\n",
    "dropout3 = tf.keras.layers.Dropout(0.3, name=\"drop_some_feature4\")(dense3)\n",
    "dense4 = tf.keras.layers.Dense(16, activation = 'relu', name=\"dence_layer4\")(dropout3)\n",
    "dropout4 = tf.keras.layers.Dropout(0.3, name=\"drop_some_feature5\")(dense4)\n",
    "\n",
    "squash = tf.keras.layers.Lambda(lambda x: 9 * tf.nn.sigmoid(x) + 1)(dropout4)\n",
    "\n",
    "\n",
    "#dropout2 = tf.keras.layers.Dropout(0.25, name=\"drop_some_feature2\")(dropout2)\n",
    "\n",
    "\n",
    "\n",
    "#dot = tf.keras.layers.Dot(axes=2)([user_embedding, book_embedding])\n",
    "#add = tf.keras.layers.Add()([dot, user_bias, book_bias])\n",
    "#flatten = tf.keras.layers.Flatten()(add)\n",
    "#con = tf.keras.layers.concatenate([flatten,dropout2])\n",
    "#dense2 = tf.keras.layers.Dense(100, activation = 'relu', name=\"dence_layer\")(con)\n",
    "#dropout2 = tf.keras.layers.Dropout(0.2, name=\"drop_some_feature3\")(dense2)\n",
    "\n",
    "#squash = tf.keras.layers.Lambda(lambda x: 9 * tf.nn.sigmoid(x) + 1)(con)\n",
    "\n",
    "model = tf.keras.Model(inputs=[user_input, book_input,feature_input], outputs=squash)\n",
    "\n",
    "\n",
    "model.compile(loss=\"mse\", metrics=[tf.keras.metrics.MeanAbsoluteError(),tf.keras.metrics.RootMeanSquaredError()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad5c5404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " user (InputLayer)           [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " book (InputLayer)           [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " integer_lookup_4 (IntegerL  (None, 1)                    0         ['user[0][0]']                \n",
      " ookup)                                                                                           \n",
      "                                                                                                  \n",
      " integer_lookup_5 (IntegerL  (None, 1)                    0         ['book[0][0]']                \n",
      " ookup)                                                                                           \n",
      "                                                                                                  \n",
      " embedding_8 (Embedding)     (None, 1, 32)                767456    ['integer_lookup_4[0][0]']    \n",
      "                                                                                                  \n",
      " embedding_10 (Embedding)    (None, 1, 32)                953120    ['integer_lookup_5[0][0]']    \n",
      "                                                                                                  \n",
      " user_book_data (InputLayer  [(None, 230)]                0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dot_2 (Dot)                 (None, 1, 1)                 0         ['embedding_8[0][0]',         \n",
      "                                                                     'embedding_10[0][0]']        \n",
      "                                                                                                  \n",
      " embedding_9 (Embedding)     (None, 1, 1)                 23983     ['integer_lookup_4[0][0]']    \n",
      "                                                                                                  \n",
      " embedding_11 (Embedding)    (None, 1, 1)                 29785     ['integer_lookup_5[0][0]']    \n",
      "                                                                                                  \n",
      " add_some_feature (Dense)    (None, 200)                  46200     ['user_book_data[0][0]']      \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, 1, 1)                 0         ['dot_2[0][0]',               \n",
      "                                                                     'embedding_9[0][0]',         \n",
      "                                                                     'embedding_11[0][0]']        \n",
      "                                                                                                  \n",
      " drop_some_feature (Dropout  (None, 200)                  0         ['add_some_feature[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)         (None, 1)                    0         ['add_2[0][0]']               \n",
      "                                                                                                  \n",
      " add_some_feature2 (Dense)   (None, 64)                   12864     ['drop_some_feature[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 65)                   0         ['flatten_2[0][0]',           \n",
      " )                                                                   'add_some_feature2[0][0]']   \n",
      "                                                                                                  \n",
      " dence_layer2 (Dense)        (None, 128)                  8448      ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      " drop_some_feature3 (Dropou  (None, 128)                  0         ['dence_layer2[0][0]']        \n",
      " t)                                                                                               \n",
      "                                                                                                  \n",
      " dence_layer3 (Dense)        (None, 64)                   8256      ['drop_some_feature3[0][0]']  \n",
      "                                                                                                  \n",
      " drop_some_feature4 (Dropou  (None, 64)                   0         ['dence_layer3[0][0]']        \n",
      " t)                                                                                               \n",
      "                                                                                                  \n",
      " dence_layer4 (Dense)        (None, 16)                   1040      ['drop_some_feature4[0][0]']  \n",
      "                                                                                                  \n",
      " drop_some_feature5 (Dropou  (None, 16)                   0         ['dence_layer4[0][0]']        \n",
      " t)                                                                                               \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)           (None, 16)                   0         ['drop_some_feature5[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1851152 (7.06 MB)\n",
      "Trainable params: 1851152 (7.06 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f57acd7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1164/1164 [==============================] - 23s 16ms/step - loss: 4.6601 - mean_absolute_error: 1.7444 - root_mean_squared_error: 2.1587 - val_loss: 3.1517 - val_mean_absolute_error: 1.4580 - val_root_mean_squared_error: 1.7753\n",
      "Epoch 2/30\n",
      "1164/1164 [==============================] - 12s 11ms/step - loss: 4.2731 - mean_absolute_error: 1.6274 - root_mean_squared_error: 2.0671 - val_loss: 2.9671 - val_mean_absolute_error: 1.3936 - val_root_mean_squared_error: 1.7225\n",
      "Epoch 3/30\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 3.9745 - mean_absolute_error: 1.5246 - root_mean_squared_error: 1.9936 - val_loss: 2.9886 - val_mean_absolute_error: 1.3944 - val_root_mean_squared_error: 1.7288\n",
      "Epoch 4/30\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 3.6755 - mean_absolute_error: 1.4162 - root_mean_squared_error: 1.9171 - val_loss: 3.0045 - val_mean_absolute_error: 1.3808 - val_root_mean_squared_error: 1.7333\n",
      "Epoch 5/30\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 3.3882 - mean_absolute_error: 1.3120 - root_mean_squared_error: 1.8407 - val_loss: 3.1908 - val_mean_absolute_error: 1.4304 - val_root_mean_squared_error: 1.7863\n",
      "Epoch 6/30\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 3.1700 - mean_absolute_error: 1.2260 - root_mean_squared_error: 1.7804 - val_loss: 3.1671 - val_mean_absolute_error: 1.4119 - val_root_mean_squared_error: 1.7796\n",
      "Epoch 7/30\n",
      "1164/1164 [==============================] - 13s 11ms/step - loss: 3.0124 - mean_absolute_error: 1.1590 - root_mean_squared_error: 1.7356 - val_loss: 3.2187 - val_mean_absolute_error: 1.4127 - val_root_mean_squared_error: 1.7941\n",
      "Epoch 8/30\n",
      "1164/1164 [==============================] - 12s 11ms/step - loss: 2.9212 - mean_absolute_error: 1.1130 - root_mean_squared_error: 1.7092 - val_loss: 3.2080 - val_mean_absolute_error: 1.4150 - val_root_mean_squared_error: 1.7911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2d1a8098400>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model.fit(\n",
    "     x={\n",
    "         \"user\": x_train[\"user_id\"],\n",
    "         \"book\": x_train[\"isbn_num\"],\n",
    "         \"user_book_data\":x_train[[str(i) for i in range(0,230)]]\n",
    "     },\n",
    "     y=y_train.values,\n",
    "     batch_size=128,\n",
    "     epochs=30,\n",
    "     validation_split=0.1, # for early stopping\n",
    "     callbacks=[\n",
    "         tf.keras.callbacks.EarlyStopping(patience=6, restore_best_weights=True)\n",
    "     ],\n",
    " )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1aecf9a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yotam\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('deep_model_emmbeding.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c81b423a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1293/1293 [==============================] - 3s 2ms/step - loss: 3.0212 - mean_absolute_error: 1.4065 - root_mean_squared_error: 1.7382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.021188497543335, 1.4065338373184204, 1.7381566762924194]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate({\n",
    "    \"user\": x_test[\"user_id\"],#.reshape(-1, 1), # fill user 1 in many times\n",
    "    \"book\": x_test[\"isbn_num\"],#.reshape(-1, 1),\n",
    "    \"user_book_data\":x_test[[str(i) for i in range(0,230)]]\n",
    "},y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1379dea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1293/1293 [==============================] - 2s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict({\n",
    "    \"user\": x_test[\"user_id\"],#.reshape(-1, 1), # fill user 1 in many times\n",
    "    \"book\": x_test[\"isbn_num\"],#.reshape(-1, 1),\n",
    "    \"user_book_data\":x_test[[str(i) for i in range(0,230)]]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dae8e1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.5 , 9.991598\n"
     ]
    }
   ],
   "source": [
    "minp = 99\n",
    "maxp =0\n",
    "for i in range(len(pred)):\n",
    "    for j in range(len(pred[i])):\n",
    "        minp = min(minp,pred[i][j])\n",
    "        maxp = max(maxp,pred[i][j])\n",
    "print(minp,\",\",maxp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94ca5e1",
   "metadata": {},
   "source": [
    "### with country and lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d22a96d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'author_num'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(x_train.columns)[250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a7387c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = tf.keras.layers.Input(shape=(1,), name=\"user\")\n",
    "user_as_integer = tf.keras.layers.IntegerLookup(vocabulary=all_users)(user_input)\n",
    "user_embedding = tf.keras.layers.Embedding(input_dim=len(all_users) + 1, output_dim=32)(user_as_integer)\n",
    "user_bias = tf.keras.layers.Embedding(input_dim=len(all_users) + 1, output_dim=1)(user_as_integer)\n",
    "\n",
    "book_input = tf.keras.layers.Input(shape=(1,), name=\"book\")\n",
    "book_as_integer = tf.keras.layers.IntegerLookup(vocabulary=all_books)(book_input)\n",
    "book_embedding = tf.keras.layers.Embedding(input_dim=len(all_books) + 1, output_dim=32)(book_as_integer)\n",
    "book_bias = tf.keras.layers.Embedding(input_dim=len(all_books) + 1, output_dim=1)(book_as_integer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "feature_input = tf.keras.layers.Input(shape=(230,), name=\"book_data\")\n",
    "feature = tf.keras.layers.Dense(200, name=\"add_some_feature\")(feature_input)\n",
    "dropout1 = tf.keras.layers.Dropout(0.3, name=\"drop_some_feature\")(feature)\n",
    "feature2 = tf.keras.layers.Dense(64, activation = 'relu', name=\"add_some_feature2\")(dropout1)\n",
    "\n",
    "user_feature_input = tf.keras.layers.Input(shape=(176,), name=\"user_data\")\n",
    "feature_u = tf.keras.layers.Dense(128, name=\"add_some_feature_u\")(user_feature_input)\n",
    "dropout1_u = tf.keras.layers.Dropout(0.4, name=\"drop_some_feature_u\")(feature_u)\n",
    "feature2_u = tf.keras.layers.Dense(64, activation = 'relu', name=\"add_some_feature2_u\")(dropout1_u)\n",
    "\n",
    "\n",
    "dot = tf.keras.layers.Dot(axes=2)([user_embedding, book_embedding])\n",
    "add = tf.keras.layers.Add()([dot, user_bias, book_bias])\n",
    "flatten = tf.keras.layers.Flatten()(add)\n",
    "con_book_users = tf.keras.layers.concatenate([feature2,feature2_u])\n",
    "feature2_u = tf.keras.layers.Dense(128, activation = 'relu', name=\"reader_book_type\")(con_book_users)\n",
    "\n",
    "con = tf.keras.layers.concatenate([flatten,feature2_u])#,feature2_u])\n",
    "dense2 = tf.keras.layers.Dense(128, activation = 'relu', name=\"dence_layer2\")(con)\n",
    "dropout2 = tf.keras.layers.Dropout(0.3, name=\"drop_some_feature3\")(dense2)\n",
    "dense3 = tf.keras.layers.Dense(64, activation = 'relu', name=\"dence_layer3\")(dropout2)\n",
    "dropout3 = tf.keras.layers.Dropout(0.3, name=\"drop_some_feature4\")(dense3)\n",
    "dense4 = tf.keras.layers.Dense(16, activation = 'relu', name=\"dence_layer4\")(dropout3)\n",
    "dropout4 = tf.keras.layers.Dropout(0.3, name=\"drop_some_feature5\")(dense4)\n",
    "\n",
    "squash = tf.keras.layers.Lambda(lambda x: 9 * tf.nn.sigmoid(x) + 1)(dropout4)\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=[user_input, book_input,feature_input,user_feature_input], outputs=squash)\n",
    "\n",
    "\n",
    "model.compile(loss=\"mse\", metrics=[tf.keras.metrics.MeanAbsoluteError(),tf.keras.metrics.RootMeanSquaredError()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1429e70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " user (InputLayer)           [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " book (InputLayer)           [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " book_data (InputLayer)      [(None, 230)]                0         []                            \n",
      "                                                                                                  \n",
      " user_data (InputLayer)      [(None, 176)]                0         []                            \n",
      "                                                                                                  \n",
      " integer_lookup (IntegerLoo  (None, 1)                    0         ['user[0][0]']                \n",
      " kup)                                                                                             \n",
      "                                                                                                  \n",
      " integer_lookup_1 (IntegerL  (None, 1)                    0         ['book[0][0]']                \n",
      " ookup)                                                                                           \n",
      "                                                                                                  \n",
      " add_some_feature (Dense)    (None, 200)                  46200     ['book_data[0][0]']           \n",
      "                                                                                                  \n",
      " add_some_feature_u (Dense)  (None, 128)                  22656     ['user_data[0][0]']           \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 1, 32)                767456    ['integer_lookup[0][0]']      \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)     (None, 1, 32)                953120    ['integer_lookup_1[0][0]']    \n",
      "                                                                                                  \n",
      " drop_some_feature (Dropout  (None, 200)                  0         ['add_some_feature[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " drop_some_feature_u (Dropo  (None, 128)                  0         ['add_some_feature_u[0][0]']  \n",
      " ut)                                                                                              \n",
      "                                                                                                  \n",
      " dot (Dot)                   (None, 1, 1)                 0         ['embedding[0][0]',           \n",
      "                                                                     'embedding_2[0][0]']         \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, 1, 1)                 23983     ['integer_lookup[0][0]']      \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)     (None, 1, 1)                 29785     ['integer_lookup_1[0][0]']    \n",
      "                                                                                                  \n",
      " add_some_feature2 (Dense)   (None, 64)                   12864     ['drop_some_feature[0][0]']   \n",
      "                                                                                                  \n",
      " add_some_feature2_u (Dense  (None, 64)                   8256      ['drop_some_feature_u[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 1, 1)                 0         ['dot[0][0]',                 \n",
      "                                                                     'embedding_1[0][0]',         \n",
      "                                                                     'embedding_3[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 128)                  0         ['add_some_feature2[0][0]',   \n",
      "                                                                     'add_some_feature2_u[0][0]'] \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 1)                    0         ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " reader_book_type (Dense)    (None, 128)                  16512     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 129)                  0         ['flatten[0][0]',             \n",
      " )                                                                   'reader_book_type[0][0]']    \n",
      "                                                                                                  \n",
      " dence_layer2 (Dense)        (None, 128)                  16640     ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " drop_some_feature3 (Dropou  (None, 128)                  0         ['dence_layer2[0][0]']        \n",
      " t)                                                                                               \n",
      "                                                                                                  \n",
      " dence_layer3 (Dense)        (None, 64)                   8256      ['drop_some_feature3[0][0]']  \n",
      "                                                                                                  \n",
      " drop_some_feature4 (Dropou  (None, 64)                   0         ['dence_layer3[0][0]']        \n",
      " t)                                                                                               \n",
      "                                                                                                  \n",
      " dence_layer4 (Dense)        (None, 16)                   1040      ['drop_some_feature4[0][0]']  \n",
      "                                                                                                  \n",
      " drop_some_feature5 (Dropou  (None, 16)                   0         ['dence_layer4[0][0]']        \n",
      " t)                                                                                               \n",
      "                                                                                                  \n",
      " lambda (Lambda)             (None, 16)                   0         ['drop_some_feature5[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1906768 (7.27 MB)\n",
      "Trainable params: 1906768 (7.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "30af5eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Language_9',\n",
       " 'Language_da',\n",
       " 'Language_de',\n",
       " 'Language_en',\n",
       " 'Language_es',\n",
       " 'Language_fr',\n",
       " 'Language_it',\n",
       " 'Language_nl',\n",
       " 'Language_ru',\n",
       " 'Language_th',\n",
       " 'country_,',\n",
       " 'country_aberdeenshire, united kingdom',\n",
       " 'country_albania',\n",
       " 'country_alderney',\n",
       " 'country_america',\n",
       " 'country_andalucia, spain',\n",
       " 'country_antarctica',\n",
       " 'country_argentina',\n",
       " 'country_aruba',\n",
       " 'country_australia',\n",
       " 'country_austria',\n",
       " 'country_bahamas',\n",
       " 'country_bahrain',\n",
       " 'country_barbados',\n",
       " 'country_belgium',\n",
       " 'country_belize',\n",
       " 'country_bermuda',\n",
       " 'country_bolivia',\n",
       " 'country_brazil',\n",
       " 'country_british columbia, canada',\n",
       " 'country_bulgaria',\n",
       " 'country_burma',\n",
       " 'country_california, usa',\n",
       " 'country_cambridgeshire, united kingdom',\n",
       " 'country_canada',\n",
       " 'country_canary islands, spain',\n",
       " 'country_cape verde',\n",
       " 'country_catalonia',\n",
       " 'country_catalunya, spain',\n",
       " 'country_cayman islands',\n",
       " 'country_chile',\n",
       " 'country_china',\n",
       " 'country_co. carlow, ireland',\n",
       " 'country_costa rica',\n",
       " 'country_cuba',\n",
       " 'country_cyprus',\n",
       " 'country_czech republic',\n",
       " 'country_dc, usa',\n",
       " 'country_denmark',\n",
       " 'country_deutschland',\n",
       " 'country_district of columbia, usa',\n",
       " 'country_dominican republic',\n",
       " 'country_ecuador',\n",
       " 'country_egypt',\n",
       " 'country_england',\n",
       " 'country_england, united kingdom',\n",
       " 'country_españa',\n",
       " 'country_euskal herria',\n",
       " 'country_everywhere and anywhere',\n",
       " 'country_far away...',\n",
       " 'country_finland',\n",
       " 'country_florida, usa',\n",
       " 'country_fort bend',\n",
       " 'country_framingham',\n",
       " 'country_france',\n",
       " 'country_germany',\n",
       " 'country_greece',\n",
       " 'country_grenada',\n",
       " 'country_guernsey',\n",
       " 'country_guernsey, channel islands',\n",
       " 'country_guinea',\n",
       " 'country_hawaii, usa',\n",
       " 'country_honduras',\n",
       " 'country_hong kong',\n",
       " 'country_hungary',\n",
       " 'country_iceland',\n",
       " 'country_iceland, iceland',\n",
       " 'country_idaho, usa',\n",
       " 'country_ile de france, france',\n",
       " 'country_illinois, usa',\n",
       " 'country_india',\n",
       " 'country_iran',\n",
       " 'country_ireland',\n",
       " 'country_israel',\n",
       " 'country_italia',\n",
       " 'country_italy',\n",
       " 'country_jamaica',\n",
       " 'country_japan',\n",
       " 'country_kazakhstan',\n",
       " 'country_kenya',\n",
       " 'country_kuwait',\n",
       " 'country_la chine éternelle!',\n",
       " 'country_laos',\n",
       " 'country_luxembourg',\n",
       " 'country_madagascar',\n",
       " 'country_malaysia',\n",
       " 'country_malta',\n",
       " 'country_maryland, usa',\n",
       " 'country_mexico',\n",
       " 'country_michigan, usa',\n",
       " 'country_moldova',\n",
       " 'country_morgan',\n",
       " 'country_n/a - on the road',\n",
       " 'country_netherlands',\n",
       " 'country_new brunswick, canada',\n",
       " 'country_new south wales, australia',\n",
       " 'country_new york, georgia, usa',\n",
       " 'country_new york, usa',\n",
       " 'country_new zealand',\n",
       " 'country_north yorkshire, united kingdom',\n",
       " 'country_norway',\n",
       " 'country_nz',\n",
       " 'country_oeiras, portugal',\n",
       " 'country_ohio, usa',\n",
       " 'country_okinawa, japan',\n",
       " 'country_ontario, canada',\n",
       " 'country_oregon, usa',\n",
       " 'country_orense',\n",
       " 'country_pakistan',\n",
       " 'country_papua new guinea',\n",
       " 'country_peru',\n",
       " 'country_philippines',\n",
       " 'country_phillipines',\n",
       " 'country_poland',\n",
       " 'country_portugal',\n",
       " 'country_puerto rico',\n",
       " 'country_qatar',\n",
       " 'country_quit',\n",
       " 'country_romania',\n",
       " 'country_russia',\n",
       " 'country_rutherford',\n",
       " 'country_saint lucia',\n",
       " 'country_saudi arabia',\n",
       " 'country_scotland',\n",
       " 'country_seoul, south korea',\n",
       " 'country_singapore',\n",
       " 'country_singapore, singapore',\n",
       " 'country_slovakia',\n",
       " 'country_slovenia',\n",
       " 'country_south africa',\n",
       " 'country_south korea',\n",
       " 'country_spain',\n",
       " 'country_sri lanka',\n",
       " 'country_sweden',\n",
       " 'country_switzerland',\n",
       " 'country_switzerland\"',\n",
       " 'country_taiwan',\n",
       " 'country_tanzania',\n",
       " 'country_tennessee, usa',\n",
       " 'country_texas, usa',\n",
       " 'country_thailand',\n",
       " 'country_tn, usa',\n",
       " 'country_trinidad and tobago',\n",
       " 'country_turkey',\n",
       " 'country_u.k.',\n",
       " 'country_u.s.a.',\n",
       " 'country_u.s>',\n",
       " 'country_ukraine',\n",
       " 'country_united kindgonm',\n",
       " 'country_united kingdom',\n",
       " 'country_united state',\n",
       " 'country_united states',\n",
       " 'country_universe',\n",
       " 'country_uruguay',\n",
       " 'country_us',\n",
       " 'country_usa',\n",
       " 'country_usa, kansas, usa',\n",
       " 'country_van wert',\n",
       " 'country_venezuela',\n",
       " 'country_vietnam',\n",
       " 'country_virginia, usa',\n",
       " 'country_wales',\n",
       " 'country_west indies, tobago',\n",
       " 'country_west yorkshire, united kingdom',\n",
       " 'country_ysa',\n",
       " 'country_nan',\n",
       " 'age',\n",
       " 'year_of_publication']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b40d443",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1164/1164 [==============================] - 18s 14ms/step - loss: 4.6415 - mean_absolute_error: 1.7400 - root_mean_squared_error: 2.1544 - val_loss: 3.2592 - val_mean_absolute_error: 1.4913 - val_root_mean_squared_error: 1.8053\n",
      "Epoch 2/100\n",
      "1164/1164 [==============================] - 21s 18ms/step - loss: 4.2664 - mean_absolute_error: 1.6238 - root_mean_squared_error: 2.0655 - val_loss: 3.1716 - val_mean_absolute_error: 1.4629 - val_root_mean_squared_error: 1.7809\n",
      "Epoch 3/100\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 3.9641 - mean_absolute_error: 1.5192 - root_mean_squared_error: 1.9910 - val_loss: 3.0105 - val_mean_absolute_error: 1.3966 - val_root_mean_squared_error: 1.7351\n",
      "Epoch 4/100\n",
      "1164/1164 [==============================] - 15s 13ms/step - loss: 3.6471 - mean_absolute_error: 1.4065 - root_mean_squared_error: 1.9097 - val_loss: 3.1164 - val_mean_absolute_error: 1.4227 - val_root_mean_squared_error: 1.7653\n",
      "Epoch 5/100\n",
      "1164/1164 [==============================] - 16s 14ms/step - loss: 3.3751 - mean_absolute_error: 1.3053 - root_mean_squared_error: 1.8371 - val_loss: 3.1729 - val_mean_absolute_error: 1.4294 - val_root_mean_squared_error: 1.7813\n",
      "Epoch 6/100\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 3.1607 - mean_absolute_error: 1.2214 - root_mean_squared_error: 1.7778 - val_loss: 3.1202 - val_mean_absolute_error: 1.3989 - val_root_mean_squared_error: 1.7664\n",
      "Epoch 7/100\n",
      "1164/1164 [==============================] - 15s 13ms/step - loss: 3.0183 - mean_absolute_error: 1.1586 - root_mean_squared_error: 1.7373 - val_loss: 3.1424 - val_mean_absolute_error: 1.3973 - val_root_mean_squared_error: 1.7727\n",
      "Epoch 8/100\n",
      "1164/1164 [==============================] - 15s 13ms/step - loss: 2.9120 - mean_absolute_error: 1.1091 - root_mean_squared_error: 1.7064 - val_loss: 3.3038 - val_mean_absolute_error: 1.4384 - val_root_mean_squared_error: 1.8176\n",
      "Epoch 9/100\n",
      "1164/1164 [==============================] - 16s 13ms/step - loss: 2.8497 - mean_absolute_error: 1.0729 - root_mean_squared_error: 1.6881 - val_loss: 3.3325 - val_mean_absolute_error: 1.4496 - val_root_mean_squared_error: 1.8255\n",
      "Epoch 10/100\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 2.8083 - mean_absolute_error: 1.0462 - root_mean_squared_error: 1.6758 - val_loss: 3.3359 - val_mean_absolute_error: 1.4468 - val_root_mean_squared_error: 1.8265\n",
      "Epoch 11/100\n",
      "1164/1164 [==============================] - 15s 13ms/step - loss: 2.7773 - mean_absolute_error: 1.0246 - root_mean_squared_error: 1.6665 - val_loss: 3.3682 - val_mean_absolute_error: 1.4422 - val_root_mean_squared_error: 1.8353\n",
      "Epoch 12/100\n",
      "1164/1164 [==============================] - 15s 13ms/step - loss: 2.7613 - mean_absolute_error: 1.0079 - root_mean_squared_error: 1.6617 - val_loss: 3.3175 - val_mean_absolute_error: 1.4425 - val_root_mean_squared_error: 1.8214\n",
      "Epoch 13/100\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 2.7419 - mean_absolute_error: 0.9932 - root_mean_squared_error: 1.6559 - val_loss: 3.3559 - val_mean_absolute_error: 1.4473 - val_root_mean_squared_error: 1.8319\n",
      "Epoch 14/100\n",
      "1164/1164 [==============================] - 15s 13ms/step - loss: 2.7308 - mean_absolute_error: 0.9821 - root_mean_squared_error: 1.6525 - val_loss: 3.3555 - val_mean_absolute_error: 1.4407 - val_root_mean_squared_error: 1.8318\n",
      "Epoch 15/100\n",
      "1164/1164 [==============================] - 15s 13ms/step - loss: 2.7194 - mean_absolute_error: 0.9742 - root_mean_squared_error: 1.6490 - val_loss: 3.3969 - val_mean_absolute_error: 1.4504 - val_root_mean_squared_error: 1.8431\n",
      "Epoch 16/100\n",
      "1164/1164 [==============================] - 14s 12ms/step - loss: 2.7140 - mean_absolute_error: 0.9685 - root_mean_squared_error: 1.6474 - val_loss: 3.3757 - val_mean_absolute_error: 1.4460 - val_root_mean_squared_error: 1.8373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d28095f250>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model.fit(\n",
    "     x={\n",
    "         \"user\": x_train[\"user_id\"],\n",
    "         \"book\": x_train[\"isbn_num\"],\n",
    "         \"book_data\":x_train[[str(i) for i in range(0,230)]], #category and summary\n",
    "         'user_data':x_train[list(x_train.columns)[251:]]#+['age','year_of_publication']] #\n",
    "     },\n",
    "     y=y_train.values,\n",
    "     batch_size=128,\n",
    "     epochs=100,\n",
    "     validation_split=0.1, # for early stopping\n",
    "     shuffle= True,\n",
    "\n",
    "     callbacks=[\n",
    "         tf.keras.callbacks.EarlyStopping(patience=13, restore_best_weights=True)\n",
    "     ],\n",
    " )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7df904a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1293/1293 [==============================] - 3s 2ms/step - loss: 3.0826 - mean_absolute_error: 1.4157 - root_mean_squared_error: 1.7557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.082643747329712, 1.4157321453094482, 1.7557458877563477]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate({\n",
    "    \"user\": x_test[\"user_id\"],#.reshape(-1, 1), # fill user 1 in many times\n",
    "    \"book\": x_test[\"isbn_num\"],#.reshape(-1, 1),\n",
    "    \"book_data\":x_test[[str(i) for i in range(0,230)]],\n",
    "    'user_data':x_test[list(x_train.columns)[251:]]\n",
    "},y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8a10738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import Input, Model\n",
    "from keras.layers import SimpleRNN, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c29e1e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yotam\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('deep_model_emmbeding_leng.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ecf4aba3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1293/1293 [==============================] - 3s 2ms/step - loss: 3.0913 - mean_absolute_error: 1.4042 - root_mean_squared_error: 1.7582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.0912551879882812, 1.404232144355774, 1.7581965923309326]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate({\n",
    "    \"user\": x_test[\"user_id\"],#.reshape(-1, 1), # fill user 1 in many times\n",
    "    \"book\": x_test[\"isbn_num\"],#.reshape(-1, 1),\n",
    "    \"user_book_data\":x_test[[str(i) for i in range(0,230)]],\n",
    "    'user_data_add':x_test[list(x_train.columns)[250:]]\n",
    "},y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8a08cf",
   "metadata": {},
   "source": [
    "## with outhers emmbeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e32adcdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>user_id</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>...</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>isbn_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>timmins, ontario, canada</td>\n",
       "      <td>34.7439</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>5</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03518</td>\n",
       "      <td>-0.125755</td>\n",
       "      <td>-0.019404</td>\n",
       "      <td>0.044569</td>\n",
       "      <td>-0.040087</td>\n",
       "      <td>0.005104</td>\n",
       "      <td>0.023391</td>\n",
       "      <td>0.116895</td>\n",
       "      <td>0.013755</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11676</td>\n",
       "      <td>n/a, n/a, n/a</td>\n",
       "      <td>34.7439</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>8</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03518</td>\n",
       "      <td>-0.125755</td>\n",
       "      <td>-0.019404</td>\n",
       "      <td>0.044569</td>\n",
       "      <td>-0.040087</td>\n",
       "      <td>0.005104</td>\n",
       "      <td>0.023391</td>\n",
       "      <td>0.116895</td>\n",
       "      <td>0.013755</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>67544</td>\n",
       "      <td>toronto, ontario, canada</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>8</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03518</td>\n",
       "      <td>-0.125755</td>\n",
       "      <td>-0.019404</td>\n",
       "      <td>0.044569</td>\n",
       "      <td>-0.040087</td>\n",
       "      <td>0.005104</td>\n",
       "      <td>0.023391</td>\n",
       "      <td>0.116895</td>\n",
       "      <td>0.013755</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>116866</td>\n",
       "      <td>ottawa, ,</td>\n",
       "      <td>34.7439</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>9</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03518</td>\n",
       "      <td>-0.125755</td>\n",
       "      <td>-0.019404</td>\n",
       "      <td>0.044569</td>\n",
       "      <td>-0.040087</td>\n",
       "      <td>0.005104</td>\n",
       "      <td>0.023391</td>\n",
       "      <td>0.116895</td>\n",
       "      <td>0.013755</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>200273</td>\n",
       "      <td>comber, ontario, canada</td>\n",
       "      <td>34.7439</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>8</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03518</td>\n",
       "      <td>-0.125755</td>\n",
       "      <td>-0.019404</td>\n",
       "      <td>0.044569</td>\n",
       "      <td>-0.040087</td>\n",
       "      <td>0.005104</td>\n",
       "      <td>0.023391</td>\n",
       "      <td>0.116895</td>\n",
       "      <td>0.013755</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 251 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index  user_id                  location      age        isbn  \\\n",
       "0           0      0        8  timmins, ontario, canada  34.7439  0002005018   \n",
       "1           2      2    11676             n/a, n/a, n/a  34.7439  0002005018   \n",
       "2           4      4    67544  toronto, ontario, canada  30.0000  0002005018   \n",
       "3           7      7   116866                 ottawa, ,  34.7439  0002005018   \n",
       "4           9      9   200273   comber, ontario, canada  34.7439  0002005018   \n",
       "\n",
       "   rating    book_title           book_author  year_of_publication  ...  \\\n",
       "0       5  Clara Callan  Richard Bruce Wright               2001.0  ...   \n",
       "1       8  Clara Callan  Richard Bruce Wright               2001.0  ...   \n",
       "2       8  Clara Callan  Richard Bruce Wright               2001.0  ...   \n",
       "3       9  Clara Callan  Richard Bruce Wright               2001.0  ...   \n",
       "4       8  Clara Callan  Richard Bruce Wright               2001.0  ...   \n",
       "\n",
       "       221       222       223       224       225       226       227  \\\n",
       "0  0.03518 -0.125755 -0.019404  0.044569 -0.040087  0.005104  0.023391   \n",
       "1  0.03518 -0.125755 -0.019404  0.044569 -0.040087  0.005104  0.023391   \n",
       "2  0.03518 -0.125755 -0.019404  0.044569 -0.040087  0.005104  0.023391   \n",
       "3  0.03518 -0.125755 -0.019404  0.044569 -0.040087  0.005104  0.023391   \n",
       "4  0.03518 -0.125755 -0.019404  0.044569 -0.040087  0.005104  0.023391   \n",
       "\n",
       "        228       229 isbn_num  \n",
       "0  0.116895  0.013755        0  \n",
       "1  0.116895  0.013755        0  \n",
       "2  0.116895  0.013755        0  \n",
       "3  0.116895  0.013755        0  \n",
       "4  0.116895  0.013755        0  \n",
       "\n",
       "[5 rows x 251 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7f2dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e039ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = tf.keras.layers.Input(shape=(1,), name=\"user\")\n",
    "user_as_integer = tf.keras.layers.IntegerLookup(vocabulary=all_users)(user_input)\n",
    "user_embedding = tf.keras.layers.Embedding(input_dim=len(all_users) + 1, output_dim=32)(user_as_integer)\n",
    "user_bias = tf.keras.layers.Embedding(input_dim=len(all_users) + 1, output_dim=1)(user_as_integer)\n",
    "\n",
    "book_input = tf.keras.layers.Input(shape=(1,), name=\"book\")\n",
    "book_as_integer = tf.keras.layers.IntegerLookup(vocabulary=all_books)(book_input)\n",
    "book_embedding = tf.keras.layers.Embedding(input_dim=len(all_books) + 1, output_dim=32)(book_as_integer)\n",
    "book_bias = tf.keras.layers.Embedding(input_dim=len(all_books) + 1, output_dim=1)(book_as_integer)\n",
    "\n",
    "author_input = tf.keras.layers.Input(shape=(1,), name=\"author\")\n",
    "author_as_integer = tf.keras.layers.IntegerLookup(vocabulary=all_authors)(author_input)\n",
    "author_embedding = tf.keras.layers.Embedding(input_dim=len(all_authors) + 1, output_dim=32)(author_as_integer)\n",
    "\n",
    "dot_author = tf.keras.layers.Dot(axes=2)([user_embedding, author_embedding])\n",
    "flatten_author = tf.keras.layers.Flatten()(dot_author)\n",
    "\n",
    "\n",
    "feature_input = tf.keras.layers.Input(shape=(230,), name=\"book_data\")\n",
    "feature = tf.keras.layers.Dense(200, name=\"add_some_feature\")(feature_input)\n",
    "dropout1 = tf.keras.layers.Dropout(0.3, name=\"drop_some_feature\")(feature)\n",
    "feature2 = tf.keras.layers.Dense(128, activation = 'relu', name=\"add_some_feature2\")(dropout1)\n",
    "dropout1_2 = tf.keras.layers.Dropout(0.3, name=\"drop_some_feature22\")(feature2)\n",
    "feature2_2 = tf.keras.layers.Dense(64, activation = 'relu', name=\"add_some_feature22\")(dropout1_2)\n",
    "\n",
    "user_feature_input = tf.keras.layers.Input(shape=(176,), name=\"user_data\")\n",
    "feature_u = tf.keras.layers.Dense(128, name=\"add_some_feature_u\")(user_feature_input)\n",
    "dropout1_u = tf.keras.layers.Dropout(0.4, name=\"drop_some_feature_u2\")(feature_u)\n",
    "feature2_u = tf.keras.layers.Dense(64, activation = 'relu', name=\"add_some_feature2_u2\")(dropout1_u)\n",
    "\n",
    "\n",
    "dot = tf.keras.layers.Dot(axes=2)([user_embedding, book_embedding])\n",
    "add = tf.keras.layers.Add()([dot, user_bias, book_bias])\n",
    "flatten = tf.keras.layers.Flatten()(add)\n",
    "con_book_users = tf.keras.layers.concatenate([feature2_2,feature2_u])\n",
    "feature2_u = tf.keras.layers.Dense(128, activation = 'relu', name=\"reader_book_type\")(con_book_users)\n",
    "\n",
    "con = tf.keras.layers.concatenate([flatten,flatten_author,feature2_u])#,feature2_u])\n",
    "dense2 = tf.keras.layers.Dense(128, activation = 'relu', name=\"dence_layer2\")(con)\n",
    "dropout2 = tf.keras.layers.Dropout(0.3, name=\"drop_some_feature3\")(dense2)\n",
    "dense3 = tf.keras.layers.Dense(64, activation = 'relu', name=\"dence_layer3\")(dropout2)\n",
    "dropout3 = tf.keras.layers.Dropout(0.3, name=\"drop_some_feature4\")(dense3)\n",
    "dense4 = tf.keras.layers.Dense(16, activation = 'relu', name=\"dence_layer4\")(dropout3)\n",
    "dropout4 = tf.keras.layers.Dropout(0.3, name=\"drop_some_feature5\")(dense4)\n",
    "dense5 = tf.keras.layers.Dense(8, activation = 'relu', name=\"dence_layer5\")(dropout4)\n",
    "dropout5 = tf.keras.layers.Dropout(0.3, name=\"drop_some_feature6\")(dense5)\n",
    "\n",
    "squash = tf.keras.layers.Lambda(lambda x: 9 * tf.nn.sigmoid(x) + 1)(dropout5)\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=[user_input, book_input,author_input,feature_input,user_feature_input], outputs=squash)\n",
    "\n",
    "\n",
    "model.compile(loss=\"mse\", metrics=[tf.keras.metrics.MeanAbsoluteError(),tf.keras.metrics.RootMeanSquaredError()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "975f8db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " book_data (InputLayer)      [(None, 230)]                0         []                            \n",
      "                                                                                                  \n",
      " add_some_feature (Dense)    (None, 200)                  46200     ['book_data[0][0]']           \n",
      "                                                                                                  \n",
      " user (InputLayer)           [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " book (InputLayer)           [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " drop_some_feature (Dropout  (None, 200)                  0         ['add_some_feature[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " user_data (InputLayer)      [(None, 176)]                0         []                            \n",
      "                                                                                                  \n",
      " integer_lookup_9 (IntegerL  (None, 1)                    0         ['user[0][0]']                \n",
      " ookup)                                                                                           \n",
      "                                                                                                  \n",
      " integer_lookup_10 (Integer  (None, 1)                    0         ['book[0][0]']                \n",
      " Lookup)                                                                                          \n",
      "                                                                                                  \n",
      " author (InputLayer)         [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " add_some_feature2 (Dense)   (None, 128)                  25728     ['drop_some_feature[0][0]']   \n",
      "                                                                                                  \n",
      " add_some_feature_u (Dense)  (None, 128)                  22656     ['user_data[0][0]']           \n",
      "                                                                                                  \n",
      " embedding_15 (Embedding)    (None, 1, 32)                767456    ['integer_lookup_9[0][0]']    \n",
      "                                                                                                  \n",
      " embedding_17 (Embedding)    (None, 1, 32)                953120    ['integer_lookup_10[0][0]']   \n",
      "                                                                                                  \n",
      " integer_lookup_11 (Integer  (None, 1)                    0         ['author[0][0]']              \n",
      " Lookup)                                                                                          \n",
      "                                                                                                  \n",
      " drop_some_feature22 (Dropo  (None, 128)                  0         ['add_some_feature2[0][0]']   \n",
      " ut)                                                                                              \n",
      "                                                                                                  \n",
      " drop_some_feature_u2 (Drop  (None, 128)                  0         ['add_some_feature_u[0][0]']  \n",
      " out)                                                                                             \n",
      "                                                                                                  \n",
      " dot_7 (Dot)                 (None, 1, 1)                 0         ['embedding_15[0][0]',        \n",
      "                                                                     'embedding_17[0][0]']        \n",
      "                                                                                                  \n",
      " embedding_16 (Embedding)    (None, 1, 1)                 23983     ['integer_lookup_9[0][0]']    \n",
      "                                                                                                  \n",
      " embedding_18 (Embedding)    (None, 1, 1)                 29785     ['integer_lookup_10[0][0]']   \n",
      "                                                                                                  \n",
      " embedding_19 (Embedding)    (None, 1, 32)                312480    ['integer_lookup_11[0][0]']   \n",
      "                                                                                                  \n",
      " add_some_feature22 (Dense)  (None, 64)                   8256      ['drop_some_feature22[0][0]'] \n",
      "                                                                                                  \n",
      " add_some_feature2_u2 (Dens  (None, 64)                   8256      ['drop_some_feature_u2[0][0]']\n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " add_3 (Add)                 (None, 1, 1)                 0         ['dot_7[0][0]',               \n",
      "                                                                     'embedding_16[0][0]',        \n",
      "                                                                     'embedding_18[0][0]']        \n",
      "                                                                                                  \n",
      " dot_6 (Dot)                 (None, 1, 1)                 0         ['embedding_15[0][0]',        \n",
      "                                                                     'embedding_19[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 128)                  0         ['add_some_feature22[0][0]',  \n",
      " )                                                                   'add_some_feature2_u2[0][0]']\n",
      "                                                                                                  \n",
      " flatten_7 (Flatten)         (None, 1)                    0         ['add_3[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)         (None, 1)                    0         ['dot_6[0][0]']               \n",
      "                                                                                                  \n",
      " reader_book_type (Dense)    (None, 128)                  16512     ['concatenate_6[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate  (None, 130)                  0         ['flatten_7[0][0]',           \n",
      " )                                                                   'flatten_6[0][0]',           \n",
      "                                                                     'reader_book_type[0][0]']    \n",
      "                                                                                                  \n",
      " dence_layer2 (Dense)        (None, 128)                  16768     ['concatenate_7[0][0]']       \n",
      "                                                                                                  \n",
      " drop_some_feature3 (Dropou  (None, 128)                  0         ['dence_layer2[0][0]']        \n",
      " t)                                                                                               \n",
      "                                                                                                  \n",
      " dence_layer3 (Dense)        (None, 64)                   8256      ['drop_some_feature3[0][0]']  \n",
      "                                                                                                  \n",
      " drop_some_feature4 (Dropou  (None, 64)                   0         ['dence_layer3[0][0]']        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " t)                                                                                               \n",
      "                                                                                                  \n",
      " dence_layer4 (Dense)        (None, 16)                   1040      ['drop_some_feature4[0][0]']  \n",
      "                                                                                                  \n",
      " drop_some_feature5 (Dropou  (None, 16)                   0         ['dence_layer4[0][0]']        \n",
      " t)                                                                                               \n",
      "                                                                                                  \n",
      " dence_layer5 (Dense)        (None, 8)                    136       ['drop_some_feature5[0][0]']  \n",
      "                                                                                                  \n",
      " drop_some_feature6 (Dropou  (None, 8)                    0         ['dence_layer5[0][0]']        \n",
      " t)                                                                                               \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)           (None, 8)                    0         ['drop_some_feature6[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2240632 (8.55 MB)\n",
      "Trainable params: 2240632 (8.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c820334b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1164/1164 [==============================] - 28s 22ms/step - loss: 4.7571 - mean_absolute_error: 1.7696 - root_mean_squared_error: 2.1811 - val_loss: 3.3345 - val_mean_absolute_error: 1.5144 - val_root_mean_squared_error: 1.8261\n",
      "Epoch 2/100\n",
      "1164/1164 [==============================] - 17s 14ms/step - loss: 4.3159 - mean_absolute_error: 1.6420 - root_mean_squared_error: 2.0775 - val_loss: 3.0891 - val_mean_absolute_error: 1.4390 - val_root_mean_squared_error: 1.7576\n",
      "Epoch 3/100\n",
      "1164/1164 [==============================] - 19s 16ms/step - loss: 3.8654 - mean_absolute_error: 1.4947 - root_mean_squared_error: 1.9661 - val_loss: 2.8875 - val_mean_absolute_error: 1.3546 - val_root_mean_squared_error: 1.6993\n",
      "Epoch 4/100\n",
      "1164/1164 [==============================] - 17s 15ms/step - loss: 3.4520 - mean_absolute_error: 1.3535 - root_mean_squared_error: 1.8580 - val_loss: 3.1410 - val_mean_absolute_error: 1.4060 - val_root_mean_squared_error: 1.7723\n",
      "Epoch 5/100\n",
      "1164/1164 [==============================] - 17s 15ms/step - loss: 3.2180 - mean_absolute_error: 1.2643 - root_mean_squared_error: 1.7939 - val_loss: 3.1159 - val_mean_absolute_error: 1.3906 - val_root_mean_squared_error: 1.7652\n",
      "Epoch 6/100\n",
      "1164/1164 [==============================] - 16s 14ms/step - loss: 3.0774 - mean_absolute_error: 1.2044 - root_mean_squared_error: 1.7543 - val_loss: 3.2450 - val_mean_absolute_error: 1.4237 - val_root_mean_squared_error: 1.8014\n",
      "Epoch 7/100\n",
      "1164/1164 [==============================] - 17s 14ms/step - loss: 2.9977 - mean_absolute_error: 1.1642 - root_mean_squared_error: 1.7314 - val_loss: 3.2831 - val_mean_absolute_error: 1.4194 - val_root_mean_squared_error: 1.8119\n",
      "Epoch 8/100\n",
      "1164/1164 [==============================] - 17s 15ms/step - loss: 2.9439 - mean_absolute_error: 1.1346 - root_mean_squared_error: 1.7158 - val_loss: 3.2131 - val_mean_absolute_error: 1.4043 - val_root_mean_squared_error: 1.7925\n",
      "Epoch 9/100\n",
      "1164/1164 [==============================] - 17s 14ms/step - loss: 2.8854 - mean_absolute_error: 1.1026 - root_mean_squared_error: 1.6987 - val_loss: 3.2582 - val_mean_absolute_error: 1.4157 - val_root_mean_squared_error: 1.8051\n",
      "Epoch 10/100\n",
      "1164/1164 [==============================] - 17s 14ms/step - loss: 2.8596 - mean_absolute_error: 1.0841 - root_mean_squared_error: 1.6910 - val_loss: 3.2621 - val_mean_absolute_error: 1.4070 - val_root_mean_squared_error: 1.8061\n",
      "Epoch 11/100\n",
      "1164/1164 [==============================] - 17s 14ms/step - loss: 2.8387 - mean_absolute_error: 1.0691 - root_mean_squared_error: 1.6848 - val_loss: 3.1770 - val_mean_absolute_error: 1.3961 - val_root_mean_squared_error: 1.7824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d2d949a0d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model.fit(\n",
    "     x={\n",
    "         \"user\": x_train[\"user_id\"],\n",
    "         \"book\": x_train[\"isbn_num\"],\n",
    "         \"author\":x_train['author_num'],\n",
    "         \"book_data\":x_train[[str(i) for i in range(0,230)]], #category and summary\n",
    "         'user_data':x_train[list(x_train.columns)[251:]]#+['age','year_of_publication']] #\n",
    "     },\n",
    "     y=y_train.values,\n",
    "     batch_size=128,\n",
    "     epochs=100,\n",
    "     validation_split=0.1, # for early stopping\n",
    "     shuffle= True,\n",
    "     callbacks=[\n",
    "         tf.keras.callbacks.EarlyStopping(patience=8, restore_best_weights=True)\n",
    "     ],\n",
    " )\n",
    "# לשקול לעשות פה שאפל מוגדר בוולידיישן, יש בעיה עם זה שלא עושים שאפל\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1893ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1293/1293 [==============================] - 3s 2ms/step - loss: 2.9318 - mean_absolute_error: 1.3649 - root_mean_squared_error: 1.7122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.9317548274993896, 1.3649042844772339, 1.712236762046814]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate({\n",
    "    \"user\": x_test[\"user_id\"],#.reshape(-1, 1), # fill user 1 in many times\n",
    "    \"book\": x_test[\"isbn_num\"],#.reshape(-1, 1),\n",
    "    \"author\":x_test['author_num'],\n",
    "    \"book_data\":x_test[[str(i) for i in range(0,230)]],\n",
    "    'user_data':x_test[list(x_train.columns)[251:]]\n",
    "},y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f876c4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yotam\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('deep_model_emmbeding_author.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c465af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['author_num',\n",
       " 'Language_9',\n",
       " 'Language_da',\n",
       " 'Language_de',\n",
       " 'Language_en',\n",
       " 'Language_es',\n",
       " 'Language_fr',\n",
       " 'Language_it',\n",
       " 'Language_nl',\n",
       " 'Language_ru',\n",
       " 'Language_th',\n",
       " 'country_,',\n",
       " 'country_aberdeenshire, united kingdom',\n",
       " 'country_albania',\n",
       " 'country_alderney',\n",
       " 'country_america',\n",
       " 'country_andalucia, spain',\n",
       " 'country_antarctica',\n",
       " 'country_argentina',\n",
       " 'country_aruba',\n",
       " 'country_australia',\n",
       " 'country_austria',\n",
       " 'country_bahamas',\n",
       " 'country_bahrain',\n",
       " 'country_barbados',\n",
       " 'country_belgium',\n",
       " 'country_belize',\n",
       " 'country_bermuda',\n",
       " 'country_bolivia',\n",
       " 'country_brazil',\n",
       " 'country_british columbia, canada',\n",
       " 'country_bulgaria',\n",
       " 'country_burma',\n",
       " 'country_california, usa',\n",
       " 'country_cambridgeshire, united kingdom',\n",
       " 'country_canada',\n",
       " 'country_canary islands, spain',\n",
       " 'country_cape verde',\n",
       " 'country_catalonia',\n",
       " 'country_catalunya, spain',\n",
       " 'country_cayman islands',\n",
       " 'country_chile',\n",
       " 'country_china',\n",
       " 'country_co. carlow, ireland',\n",
       " 'country_costa rica',\n",
       " 'country_cuba',\n",
       " 'country_cyprus',\n",
       " 'country_czech republic',\n",
       " 'country_dc, usa',\n",
       " 'country_denmark',\n",
       " 'country_deutschland',\n",
       " 'country_district of columbia, usa',\n",
       " 'country_dominican republic',\n",
       " 'country_ecuador',\n",
       " 'country_egypt',\n",
       " 'country_england',\n",
       " 'country_england, united kingdom',\n",
       " 'country_españa',\n",
       " 'country_euskal herria',\n",
       " 'country_everywhere and anywhere',\n",
       " 'country_far away...',\n",
       " 'country_finland',\n",
       " 'country_florida, usa',\n",
       " 'country_fort bend',\n",
       " 'country_framingham',\n",
       " 'country_france',\n",
       " 'country_germany',\n",
       " 'country_greece',\n",
       " 'country_grenada',\n",
       " 'country_guernsey',\n",
       " 'country_guernsey, channel islands',\n",
       " 'country_guinea',\n",
       " 'country_hawaii, usa',\n",
       " 'country_honduras',\n",
       " 'country_hong kong',\n",
       " 'country_hungary',\n",
       " 'country_iceland',\n",
       " 'country_iceland, iceland',\n",
       " 'country_idaho, usa',\n",
       " 'country_ile de france, france',\n",
       " 'country_illinois, usa',\n",
       " 'country_india',\n",
       " 'country_iran',\n",
       " 'country_ireland',\n",
       " 'country_israel',\n",
       " 'country_italia',\n",
       " 'country_italy',\n",
       " 'country_jamaica',\n",
       " 'country_japan',\n",
       " 'country_kazakhstan',\n",
       " 'country_kenya',\n",
       " 'country_kuwait',\n",
       " 'country_la chine éternelle!',\n",
       " 'country_laos',\n",
       " 'country_luxembourg',\n",
       " 'country_madagascar',\n",
       " 'country_malaysia',\n",
       " 'country_malta',\n",
       " 'country_maryland, usa',\n",
       " 'country_mexico',\n",
       " 'country_michigan, usa',\n",
       " 'country_moldova',\n",
       " 'country_morgan',\n",
       " 'country_n/a - on the road',\n",
       " 'country_netherlands',\n",
       " 'country_new brunswick, canada',\n",
       " 'country_new south wales, australia',\n",
       " 'country_new york, georgia, usa',\n",
       " 'country_new york, usa',\n",
       " 'country_new zealand',\n",
       " 'country_north yorkshire, united kingdom',\n",
       " 'country_norway',\n",
       " 'country_nz',\n",
       " 'country_oeiras, portugal',\n",
       " 'country_ohio, usa',\n",
       " 'country_okinawa, japan',\n",
       " 'country_ontario, canada',\n",
       " 'country_oregon, usa',\n",
       " 'country_orense',\n",
       " 'country_pakistan',\n",
       " 'country_papua new guinea',\n",
       " 'country_peru',\n",
       " 'country_philippines',\n",
       " 'country_phillipines',\n",
       " 'country_poland',\n",
       " 'country_portugal',\n",
       " 'country_puerto rico',\n",
       " 'country_qatar',\n",
       " 'country_quit',\n",
       " 'country_romania',\n",
       " 'country_russia',\n",
       " 'country_rutherford',\n",
       " 'country_saint lucia',\n",
       " 'country_saudi arabia',\n",
       " 'country_scotland',\n",
       " 'country_seoul, south korea',\n",
       " 'country_singapore',\n",
       " 'country_singapore, singapore',\n",
       " 'country_slovakia',\n",
       " 'country_slovenia',\n",
       " 'country_south africa',\n",
       " 'country_south korea',\n",
       " 'country_spain',\n",
       " 'country_sri lanka',\n",
       " 'country_sweden',\n",
       " 'country_switzerland',\n",
       " 'country_switzerland\"',\n",
       " 'country_taiwan',\n",
       " 'country_tanzania',\n",
       " 'country_tennessee, usa',\n",
       " 'country_texas, usa',\n",
       " 'country_thailand',\n",
       " 'country_tn, usa',\n",
       " 'country_trinidad and tobago',\n",
       " 'country_turkey',\n",
       " 'country_u.k.',\n",
       " 'country_u.s.a.',\n",
       " 'country_u.s>',\n",
       " 'country_ukraine',\n",
       " 'country_united kindgonm',\n",
       " 'country_united kingdom',\n",
       " 'country_united state',\n",
       " 'country_united states',\n",
       " 'country_universe',\n",
       " 'country_uruguay',\n",
       " 'country_us',\n",
       " 'country_usa',\n",
       " 'country_usa, kansas, usa',\n",
       " 'country_van wert',\n",
       " 'country_venezuela',\n",
       " 'country_vietnam',\n",
       " 'country_virginia, usa',\n",
       " 'country_wales',\n",
       " 'country_west indies, tobago',\n",
       " 'country_west yorkshire, united kingdom',\n",
       " 'country_ysa',\n",
       " 'country_nan']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(x_train.columns)[250:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ab6e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6831 real val, 3166 with \"a book cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc7b6886",
   "metadata": {},
   "outputs": [],
   "source": [
    "car = pd.read_csv(r'cover_page.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3bc6137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>img_l</th>\n",
       "      <th>cover_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>a close up of a book cover with two women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>http://images.amazon.com/images/P/0440234743.0...</td>\n",
       "      <td>a book cover of the testament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>http://images.amazon.com/images/P/0345417623.0...</td>\n",
       "      <td>a book cover of time line by michael crichton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>http://images.amazon.com/images/P/0312978383.0...</td>\n",
       "      <td>a book cover of winter solstice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>http://images.amazon.com/images/P/0553264990.0...</td>\n",
       "      <td>a book cover of the last of the breed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7586</th>\n",
       "      <td>7586</td>\n",
       "      <td>http://images.amazon.com/images/P/0448095122.0...</td>\n",
       "      <td>a close up of a book cover with a woman in a tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7587</th>\n",
       "      <td>7587</td>\n",
       "      <td>http://images.amazon.com/images/P/0451525264.0...</td>\n",
       "      <td>a book cover with a picture of a child holding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7588</th>\n",
       "      <td>7588</td>\n",
       "      <td>http://images.amazon.com/images/P/0553272500.0...</td>\n",
       "      <td>a book cover of cheaper by the dozen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7597</th>\n",
       "      <td>7597</td>\n",
       "      <td>http://images.amazon.com/images/P/0816713170.0...</td>\n",
       "      <td>a book cover of a man leaning on a drum in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7600</th>\n",
       "      <td>7600</td>\n",
       "      <td>http://images.amazon.com/images/P/0875420486.0...</td>\n",
       "      <td>a book cover with candles and books on a table</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3166 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                              img_l  \\\n",
       "0              0  http://images.amazon.com/images/P/0002005018.0...   \n",
       "5              5  http://images.amazon.com/images/P/0440234743.0...   \n",
       "12            12  http://images.amazon.com/images/P/0345417623.0...   \n",
       "13            13  http://images.amazon.com/images/P/0312978383.0...   \n",
       "15            15  http://images.amazon.com/images/P/0553264990.0...   \n",
       "...          ...                                                ...   \n",
       "7586        7586  http://images.amazon.com/images/P/0448095122.0...   \n",
       "7587        7587  http://images.amazon.com/images/P/0451525264.0...   \n",
       "7588        7588  http://images.amazon.com/images/P/0553272500.0...   \n",
       "7597        7597  http://images.amazon.com/images/P/0816713170.0...   \n",
       "7600        7600  http://images.amazon.com/images/P/0875420486.0...   \n",
       "\n",
       "                                             cover_page  \n",
       "0             a close up of a book cover with two women  \n",
       "5                         a book cover of the testament  \n",
       "12        a book cover of time line by michael crichton  \n",
       "13                      a book cover of winter solstice  \n",
       "15                a book cover of the last of the breed  \n",
       "...                                                 ...  \n",
       "7586  a close up of a book cover with a woman in a tree  \n",
       "7587  a book cover with a picture of a child holding...  \n",
       "7588               a book cover of cheaper by the dozen  \n",
       "7597  a book cover of a man leaning on a drum in the...  \n",
       "7600     a book cover with candles and books on a table  \n",
       "\n",
       "[3166 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car[car['cover_page'].str.contains('a book cover')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
