{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, pydot, graphviz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "# Split the data into train and test sets\n",
    "# importing relevant libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from book_funcs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pydot\n",
    "import pydotplus\n",
    "from pydotplus import graphviz\n",
    "from keras.utils import plot_model\n",
    "from keras.utils import model_to_dot\n",
    "keras.utils.pydot = pydot\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from lightfm import LightFM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/royzalta/Downloads/df_clean_after_pca')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the rows with rating = 0\n",
    "df = df[df['rating']!=0]\n",
    "df_isbn = df['isbn']\n",
    "num_dict = {}\n",
    "# Create a dictionary of unique isbn values\n",
    "for i,j in enumerate(df_isbn.unique()):\n",
    "    num_dict[j]=i\n",
    "df['isbn_num'] = df['isbn'].apply(lambda txt: num_dict[txt])\n",
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a unique books autor id\n",
    "book_author = df['book_author']\n",
    "num_dict = {}\n",
    "for i,j in enumerate(book_author.unique()):\n",
    "    num_dict[j]=i\n",
    "df['author_num'] = df['book_author'].apply(lambda txt: num_dict[txt])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train and test\n",
    "df =reader_encode(df)\n",
    "train_users, test_users = train_test_split(df, test_size = 0.2 , random_state= 42)\n",
    "x_train = train_users.drop(columns=['rating'])\n",
    "y_train = train_users[\"rating\"]\n",
    "\n",
    "x_test = test_users.drop(columns=['rating'])\n",
    "y_test = test_users[\"rating\"]\n",
    "\n",
    "all_users = train_users[\"user_id\"].unique()\n",
    "all_books = train_users[\"isbn_num\"].unique()\n",
    "all_authors = train_users[\"author_num\"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implemention of LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding for user\n",
    "user_input = tf.keras.layers.Input(shape=(1,), name=\"user\")\n",
    "user_as_integer = tf.keras.layers.IntegerLookup(vocabulary=all_users)(user_input)\n",
    "user_embedding = tf.keras.layers.Embedding(input_dim=len(all_users) + 1, output_dim=32)(user_as_integer)\n",
    "user_bias = tf.keras.layers.Embedding(input_dim=len(all_users) + 1, output_dim=1)(user_as_integer)\n",
    "# embedding for book\n",
    "book_input = tf.keras.layers.Input(shape=(1,), name=\"book\")\n",
    "book_as_integer = tf.keras.layers.IntegerLookup(vocabulary=all_books)(book_input)\n",
    "book_embedding = tf.keras.layers.Embedding(input_dim=len(all_books) + 1, output_dim=32)(book_as_integer)\n",
    "book_bias = tf.keras.layers.Embedding(input_dim=len(all_books) + 1, output_dim=1)(book_as_integer)\n",
    "\n",
    "# embedding for author\n",
    "author_input = tf.keras.layers.Input(shape=(1,), name=\"author\")\n",
    "author_as_integer = tf.keras.layers.IntegerLookup(vocabulary=all_authors)(author_input)\n",
    "author_embedding = tf.keras.layers.Embedding(input_dim=len(all_authors) + 1, output_dim=32)(author_as_integer)\n",
    "\n",
    "dot_author = tf.keras.layers.Dot(axes=2)([user_embedding, author_embedding])\n",
    "flatten_author = tf.keras.layers.Flatten()(dot_author)\n",
    "\n",
    "\n",
    "feature_input = tf.keras.layers.Input(shape=(230,), name=\"book_data\")\n",
    "feature = tf.keras.layers.Dense(200, activation = 'relu', name=\"add_some_feature\",kernel_regularizer=l2(0.01))(feature_input)\n",
    "dropout1 = tf.keras.layers.Dropout(0.2, name=\"drop_some_feature\")(feature)\n",
    "feature2 = tf.keras.layers.Dense(128, activation = 'relu', name=\"add_some_feature2\",kernel_regularizer=l2(0.01))(dropout1)\n",
    "dropout1_2 = tf.keras.layers.Dropout(0.2, name=\"drop_some_feature22\")(feature2)\n",
    "feature2_2 = tf.keras.layers.Dense(64, activation = 'relu', name=\"add_some_feature22\",kernel_regularizer=keras.regularizers.l2(0.01))(dropout1_2)\n",
    "\n",
    "user_feature_input = tf.keras.layers.Input(shape=(176,), name=\"user_data\")\n",
    "feature_u = tf.keras.layers.Dense(128, activation = 'relu', name=\"add_some_feature_u\",kernel_regularizer=keras.regularizers.l2(0.01))(user_feature_input)\n",
    "dropout1_u = tf.keras.layers.Dropout(0.3, name=\"drop_some_feature_u2\")(feature_u)\n",
    "feature2_u = tf.keras.layers.Dense(64, activation = 'relu', name=\"add_some_feature2_u2\",kernel_regularizer=keras.regularizers.l2(0.01))(dropout1_u)\n",
    "\n",
    "\n",
    "dot = tf.keras.layers.Dot(axes=2)([user_embedding, book_embedding])\n",
    "add = tf.keras.layers.Add()([dot, user_bias, book_bias])\n",
    "flatten = tf.keras.layers.Flatten()(add)\n",
    "con_book_users = tf.keras.layers.concatenate([feature2_2,feature2_u])\n",
    "feature2_u = tf.keras.layers.Dense(128, activation = 'relu', name=\"reader_book_type\")(con_book_users)\n",
    "\n",
    "con = tf.keras.layers.concatenate([flatten,flatten_author,feature2_u])#,feature2_u])\n",
    "dense2 = tf.keras.layers.Dense(128, activation = 'relu', name=\"dence_layer2\",kernel_regularizer=keras.regularizers.l2(0.01))(con)\n",
    "dropout2 = tf.keras.layers.Dropout(0.2, name=\"drop_some_feature3\")(dense2)\n",
    "dense3 = tf.keras.layers.Dense(64, activation = 'relu', name=\"dence_layer3\",kernel_regularizer=keras.regularizers.l2(0.01))(dropout2)\n",
    "dropout3 = tf.keras.layers.Dropout(0.2, name=\"drop_some_feature4\")(dense3)\n",
    "dense4 = tf.keras.layers.Dense(16, activation = 'relu', name=\"dence_layer4\",kernel_regularizer=keras.regularizers.l2(0.01))(dropout3)\n",
    "dropout4 = tf.keras.layers.Dropout(0.2, name=\"drop_some_feature5\")(dense4)\n",
    "dense5 = tf.keras.layers.Dense(8, activation = 'relu', name=\"dence_layer5\",kernel_regularizer=keras.regularizers.l2(0.01))(dropout4)\n",
    "dropout5 = tf.keras.layers.Dropout(0.2, name=\"drop_some_feature6\")(dense5)\n",
    "\n",
    "squash = tf.keras.layers.Lambda(lambda x: 9 * tf.nn.sigmoid(x) + 1)(dropout5)\n",
    "\n",
    "\n",
    "\n",
    "model = LightFM(inputs=[user_input, book_input,author_input,feature_input,user_feature_input], outputs=squash)\n",
    "\n",
    "# add adam optimizer\n",
    "model.compile(loss=\"mse\",optimizer = 'adam', metrics=[tf.keras.metrics.MeanAbsoluteError(),tf.keras.metrics.RootMeanSquaredError()])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
